{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/qa+ZGdfZtriiBnROxQ4Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTsZP3Jjz1yK","executionInfo":{"status":"ok","timestamp":1732429981777,"user_tz":-330,"elapsed":11371,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"39a615d4-c391-49d7-d6a8-2ea4b4b3d45c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","source":["import pyspark\n"],"metadata":{"id":"CLExcENO3Xqr","executionInfo":{"status":"ok","timestamp":1732429981778,"user_tz":-330,"elapsed":7,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","type(pd.read_csv('test1.csv'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"bhxM2xO33Zma","executionInfo":{"status":"ok","timestamp":1732429983593,"user_tz":-330,"elapsed":1821,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"097a5e21-fdec-4abc-f565-87e1b550ed02"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.frame.DataFrame"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n","\n","Data structure also contains labeled axes (rows and columns).\n","Arithmetic operations align on both row and column labels. Can be\n","thought of as a dict-like container for Series objects. The primary\n","pandas data structure.\n","\n","Parameters\n","----------\n","data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n","    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n","    data is a dict, column order follows insertion-order. If a dict contains Series\n","    which have an index defined, it is aligned by its index. This alignment also\n","    occurs if data is a Series or a DataFrame itself. Alignment is done on\n","    Series/DataFrame inputs.\n","\n","    If data is a list of dicts, column order follows insertion-order.\n","\n","index : Index or array-like\n","    Index to use for resulting frame. Will default to RangeIndex if\n","    no indexing information part of input data and no index provided.\n","columns : Index or array-like\n","    Column labels to use for resulting frame when data does not have them,\n","    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n","    will perform column selection instead.\n","dtype : dtype, default None\n","    Data type to force. Only a single dtype is allowed. If None, infer.\n","copy : bool or None, default None\n","    Copy data from inputs.\n","    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n","    or 2d ndarray input, the default of None behaves like ``copy=False``.\n","    If data is a dict containing one or more Series (possibly of different dtypes),\n","    ``copy=False`` will ensure that these inputs are not copied.\n","\n","    .. versionchanged:: 1.3.0\n","\n","See Also\n","--------\n","DataFrame.from_records : Constructor from tuples, also record arrays.\n","DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n","read_csv : Read a comma-separated values (csv) file into DataFrame.\n","read_table : Read general delimited file into DataFrame.\n","read_clipboard : Read text from clipboard into DataFrame.\n","\n","Notes\n","-----\n","Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n","\n","Examples\n","--------\n","Constructing DataFrame from a dictionary.\n","\n","&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n","&gt;&gt;&gt; df = pd.DataFrame(data=d)\n","&gt;&gt;&gt; df\n","   col1  col2\n","0     1     3\n","1     2     4\n","\n","Notice that the inferred dtype is int64.\n","\n","&gt;&gt;&gt; df.dtypes\n","col1    int64\n","col2    int64\n","dtype: object\n","\n","To enforce a single dtype:\n","\n","&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n","&gt;&gt;&gt; df.dtypes\n","col1    int8\n","col2    int8\n","dtype: object\n","\n","Constructing DataFrame from a dictionary including Series:\n","\n","&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n","&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n","   col1  col2\n","0     0   NaN\n","1     1   NaN\n","2     2   2.0\n","3     3   3.0\n","\n","Constructing DataFrame from numpy ndarray:\n","\n","&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n","...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n","&gt;&gt;&gt; df2\n","   a  b  c\n","0  1  2  3\n","1  4  5  6\n","2  7  8  9\n","\n","Constructing DataFrame from a numpy ndarray that has labeled columns:\n","\n","&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n","...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n","&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n","...\n","&gt;&gt;&gt; df3\n","   c  a\n","0  3  1\n","1  6  4\n","2  9  7\n","\n","Constructing DataFrame from dataclass:\n","\n","&gt;&gt;&gt; from dataclasses import make_dataclass\n","&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n","&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n","   x  y\n","0  0  0\n","1  0  3\n","2  2  3\n","\n","Constructing DataFrame from Series/DataFrame:\n","\n","&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df\n","   0\n","a  1\n","c  3\n","\n","&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n","&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n","&gt;&gt;&gt; df2\n","   x\n","a  1\n","c  3</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 509);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"id":"vQO70m343bsh","executionInfo":{"status":"ok","timestamp":1732429983594,"user_tz":-330,"elapsed":7,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["spark=SparkSession.builder.appName('Practise').getOrCreate()"],"metadata":{"id":"ZoEBKvkk3b5V","executionInfo":{"status":"ok","timestamp":1732429998577,"user_tz":-330,"elapsed":14990,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"oHVPqVE53g9w","executionInfo":{"status":"ok","timestamp":1732429999920,"user_tz":-330,"elapsed":1350,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"19160981-2f77-4855-8b41-922d7c7c3522"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7d8fe93906d0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://6c5f8dfa634b:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Practise</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_pyspark=spark.read.csv('test1.csv')"],"metadata":{"id":"IGqCk3iF3mPD","executionInfo":{"status":"ok","timestamp":1732430008151,"user_tz":-330,"elapsed":8235,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df_pyspark=spark.read.option('header','true').csv('test1.csv')\n"],"metadata":{"id":"mMXxR6Ce3qqF","executionInfo":{"status":"ok","timestamp":1732430010999,"user_tz":-330,"elapsed":1367,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["type(df_pyspark)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"4PD_STdh3rv8","executionInfo":{"status":"ok","timestamp":1732430011000,"user_tz":-330,"elapsed":13,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"d96c08ab-9ee3-48f0-ffda-f1c519889c5e"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.sql.dataframe.DataFrame"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n","\n",".. versionadded:: 1.3.0\n","\n",".. versionchanged:: 3.4.0\n","    Supports Spark Connect.\n","\n","Examples\n","--------\n","A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n","and can be created using various functions in :class:`SparkSession`:\n","\n","&gt;&gt;&gt; people = spark.createDataFrame([\n","...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n","...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n","...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n","...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n","... ])\n","\n","Once created, it can be manipulated using the various domain-specific-language\n","(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n","\n","To select a column from the :class:`DataFrame`, use the apply method:\n","\n","&gt;&gt;&gt; age_col = people.age\n","\n","A more concrete example:\n","\n","&gt;&gt;&gt; # To create DataFrame using SparkSession\n","... department = spark.createDataFrame([\n","...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n","...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n","...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n","... ])\n","\n","&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n","...     department, people.deptId == department.id).groupBy(\n","...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n","+-------+------+-----------+--------+\n","|   name|gender|avg(salary)|max(age)|\n","+-------+------+-----------+--------+\n","|     ML|     F|      150.0|      60|\n","|PySpark|     M|       75.0|      50|\n","+-------+------+-----------+--------+\n","\n","Notes\n","-----\n","A DataFrame should only be created as described above. It should not be directly\n","created via using the constructor.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 80);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df_pyspark.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ik4jJEbr3vSK","executionInfo":{"status":"ok","timestamp":1732430011000,"user_tz":-330,"elapsed":11,"user":{"displayName":"Priyanka Dakkata","userId":"02531916807305108102"}},"outputId":"da3ea15b-d3b5-4a38-a2d1-8f03d830ff67"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Name: string (nullable = true)\n"," |-- age: string (nullable = true)\n"," |-- Experience: string (nullable = true)\n"," |-- Salary: string (nullable = true)\n","\n"]}]}]}